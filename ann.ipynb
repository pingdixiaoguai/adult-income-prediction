{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "# 导包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from plot_confusion_matrix import plot_confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "# 根据题意，先把header设置好\n",
    "headers = ['age', 'workclass', 'fnlwgt',\n",
    "           'education', 'education_num', 'marital_status',\n",
    "           'occupation', 'relationship', 'race',\n",
    "           'sex', 'capital_gain', 'capital_loss',\n",
    "           'hours_per_week', 'native_country', 'income']\n",
    "\n",
    "# 读取训练集进入内存\n",
    "train_data = pd.read_csv(\"data/adult_train.csv\",names=headers)\n",
    "\n",
    "# 对于测试集，他的第一行是一个分隔，不读入\n",
    "test_data = pd.read_csv(\"data/adult_test.csv\",names=headers,skiprows=[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "(32561, 15)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 118
    }
   ],
   "source": [
    "# 看看训练集有多少数据\n",
    "train_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "                age        fnlwgt  education_num  capital_gain  capital_loss  \\\ncount  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \nmean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \nstd       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \nmin       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \nmax       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n\n       hours_per_week  \ncount    32561.000000  \nmean        40.437456  \nstd         12.347429  \nmin          1.000000  \n25%         40.000000  \n50%         40.000000  \n75%         45.000000  \nmax         99.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>fnlwgt</th>\n      <th>education_num</th>\n      <th>capital_gain</th>\n      <th>capital_loss</th>\n      <th>hours_per_week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>32561.000000</td>\n      <td>3.256100e+04</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>38.581647</td>\n      <td>1.897784e+05</td>\n      <td>10.080679</td>\n      <td>1077.648844</td>\n      <td>87.303830</td>\n      <td>40.437456</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>13.640433</td>\n      <td>1.055500e+05</td>\n      <td>2.572720</td>\n      <td>7385.292085</td>\n      <td>402.960219</td>\n      <td>12.347429</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>17.000000</td>\n      <td>1.228500e+04</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>28.000000</td>\n      <td>1.178270e+05</td>\n      <td>9.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>37.000000</td>\n      <td>1.783560e+05</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>48.000000</td>\n      <td>2.370510e+05</td>\n      <td>12.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>45.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>90.000000</td>\n      <td>1.484705e+06</td>\n      <td>16.000000</td>\n      <td>99999.000000</td>\n      <td>4356.000000</td>\n      <td>99.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 119
    }
   ],
   "source": [
    "# 看看数据是怎么样的，平均值；最大最小值，标准差等等（只有连续性的）\n",
    "train_data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "age                 0\nworkclass         963\nfnlwgt              0\neducation           0\neducation_num       0\nmarital_status      0\noccupation        966\nrelationship        0\nrace                0\nsex                 0\ncapital_gain        0\ncapital_loss        0\nhours_per_week      0\nnative_country    274\nincome              0\ndtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 120
    }
   ],
   "source": [
    "# 数据中有一些值是？，用python的NaN代替方便以后直接当作空值处理\n",
    "train_data = train_data.replace('[?]', np.NaN, regex=True)\n",
    "test_data = test_data.replace('[?]', np.NaN, regex=True)\n",
    "# 看看数据里有NaN的各类有多少\n",
    "train_data.isnull().sum()\n",
    "test_data.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "age               0\nworkclass         0\nfnlwgt            0\neducation         0\neducation_num     0\nmarital_status    0\noccupation        0\nrelationship      0\nrace              0\nsex               0\ncapital_gain      0\ncapital_loss      0\nhours_per_week    0\nnative_country    0\nincome            0\ndtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 121
    }
   ],
   "source": [
    "# 对于缺失属性的数据直接删除\n",
    "train_data = train_data.dropna()\n",
    "train_data.isnull().sum()\n",
    "test_data = test_data.dropna()\n",
    "test_data.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "# 开始处理离散数据\n",
    "# income我们需要将其映射一下\n",
    "# 先将>=50K的映射成1，<=50K的设置为0\n",
    "income_map = {' <=50K':0,' >50K':1}\n",
    "income_map2 = {' <=50K.':0, ' >50K.':1}\n",
    "train_data['income'] = train_data['income'].map(income_map).astype(int)\n",
    "test_data['income'] = test_data['income'].map(income_map2).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "['workclass',\n 'education',\n 'marital_status',\n 'occupation',\n 'relationship',\n 'race',\n 'sex',\n 'native_country']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 123
    }
   ],
   "source": [
    "# 取出所有的离散量属性\n",
    "discrete = [x for x in train_data.columns if train_data[x].dtype=='object']\n",
    "discrete"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      " Private             22286\n",
      " Self-emp-not-inc     2499\n",
      " Local-gov            2067\n",
      " State-gov            1279\n",
      " Self-emp-inc         1074\n",
      " Federal-gov           943\n",
      " Without-pay            14\n",
      "Name: workclass, dtype: int64\n",
      " HS-grad         9840\n",
      " Some-college    6678\n",
      " Bachelors       5044\n",
      " Masters         1627\n",
      " Assoc-voc       1307\n",
      " 11th            1048\n",
      " Assoc-acdm      1008\n",
      " 10th             820\n",
      " 7th-8th          557\n",
      " Prof-school      542\n",
      " 9th              455\n",
      " 12th             377\n",
      " Doctorate        375\n",
      " 5th-6th          288\n",
      " 1st-4th          151\n",
      " Preschool         45\n",
      "Name: education, dtype: int64\n",
      " Married-civ-spouse       14065\n",
      " Never-married             9726\n",
      " Divorced                  4214\n",
      " Separated                  939\n",
      " Widowed                    827\n",
      " Married-spouse-absent      370\n",
      " Married-AF-spouse           21\n",
      "Name: marital_status, dtype: int64\n",
      " Prof-specialty       4038\n",
      " Craft-repair         4030\n",
      " Exec-managerial      3992\n",
      " Adm-clerical         3721\n",
      " Sales                3584\n",
      " Other-service        3212\n",
      " Machine-op-inspct    1966\n",
      " Transport-moving     1572\n",
      " Handlers-cleaners    1350\n",
      " Farming-fishing       989\n",
      " Tech-support          912\n",
      " Protective-serv       644\n",
      " Priv-house-serv       143\n",
      " Armed-Forces            9\n",
      "Name: occupation, dtype: int64\n",
      " Husband           12463\n",
      " Not-in-family      7726\n",
      " Own-child          4466\n",
      " Unmarried          3212\n",
      " Wife               1406\n",
      " Other-relative      889\n",
      "Name: relationship, dtype: int64\n",
      " White                 25933\n",
      " Black                  2817\n",
      " Asian-Pac-Islander      895\n",
      " Amer-Indian-Eskimo      286\n",
      " Other                   231\n",
      "Name: race, dtype: int64\n",
      " Male      20380\n",
      " Female     9782\n",
      "Name: sex, dtype: int64\n",
      " United-States                 27504\n",
      " Mexico                          610\n",
      " Philippines                     188\n",
      " Germany                         128\n",
      " Puerto-Rico                     109\n",
      " Canada                          107\n",
      " India                           100\n",
      " El-Salvador                     100\n",
      " Cuba                             92\n",
      " England                          86\n",
      " Jamaica                          80\n",
      " South                            71\n",
      " China                            68\n",
      " Italy                            68\n",
      " Dominican-Republic               67\n",
      " Vietnam                          64\n",
      " Guatemala                        63\n",
      " Japan                            59\n",
      " Poland                           56\n",
      " Columbia                         56\n",
      " Haiti                            42\n",
      " Taiwan                           42\n",
      " Iran                             42\n",
      " Portugal                         34\n",
      " Nicaragua                        33\n",
      " Peru                             30\n",
      " Greece                           29\n",
      " Ecuador                          27\n",
      " France                           27\n",
      " Ireland                          24\n",
      " Hong                             19\n",
      " Trinadad&Tobago                  18\n",
      " Cambodia                         18\n",
      " Thailand                         17\n",
      " Laos                             17\n",
      " Yugoslavia                       16\n",
      " Outlying-US(Guam-USVI-etc)       14\n",
      " Hungary                          13\n",
      " Honduras                         12\n",
      " Scotland                         11\n",
      " Holand-Netherlands                1\n",
      "Name: native_country, dtype: int64\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 看看这些离散量属性的取值分布\n",
    "for i in discrete:\n",
    "    print(train_data[i].value_counts())\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 发现有一些是比较接近重叠的，将这些重叠的归到同一类\n",
    "# 大致可以把gov有关的一类，Private一类，Self-emp一类，没工作的一类\n",
    "train_data['workclass'] = train_data['workclass'].replace([' Self-emp-not-inc', ' Self-emp-inc'],' Self-emp')\n",
    "train_data['workclass'] = train_data['workclass'].replace([' Federal-gov', ' Local-gov', ' State-gov'], ' Gov')\n",
    "train_data['workclass'] = train_data['workclass'].replace([' Without-pay', ' Never-worked'], ' Un-emp')\n",
    "train_data['workclass'].value_counts()                                                         \n",
    "\n",
    "test_data['workclass'] = test_data['workclass'].replace([' Self-emp-not-inc', ' Self-emp-inc'],' Self-emp')\n",
    "test_data['workclass'] = test_data['workclass'].replace([' Federal-gov', ' Local-gov', ' State-gov'], ' Gov')\n",
    "test_data['workclass'] = test_data['workclass'].replace([' Without-pay', ' Never-worked'], ' Un-emp')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 同理对marital_status进行归类\n",
    "train_data['marital_status'] = train_data['marital_status'].replace([' Divorced',' Married-spouse-absent',' Never-married',' Separated',' Widowed'],' Single')\n",
    "train_data['marital_status'] = train_data['marital_status'].replace([' Married-civ-spouse', ' Married-AF-spouse'], ' Couple')\n",
    "train_data['marital_status'].value_counts()\n",
    "\n",
    "test_data['marital_status'] = test_data['marital_status'].replace([' Divorced',' Married-spouse-absent',' Never-married',' Separated',' Widowed'],' Single')\n",
    "test_data['marital_status'] = test_data['marital_status'].replace([' Married-civ-spouse', ' Married-AF-spouse'], ' Couple')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# native_country这个分类太多了，而且很多类的人很少，干脆把人少的都归到other里\n",
    "train_data['native_country'] = train_data['native_country'].replace([' Holand-Netherlands',' Scotland', ' Honduras', \n",
    "                                                                     ' Hungary', ' Outlying-US(Guam-USVI-etc)', ' Yugoslavia', \n",
    "                                                                     ' Laos', ' Thailand', ' Cambodia', \n",
    "                                                                     ' Trinadad&Tobago', ' Hong', ' Ireland', \n",
    "                                                                     ' France',' Ecuador', ' Greece', ' Peru', \n",
    "                                                                     ' Nicaragua', ' Portugal', ' Iran', \n",
    "                                                                     ' Taiwan', ' Haiti'], ' Other')\n",
    "\n",
    "test_data['native_country'] = test_data['native_country'].replace([' Holand-Netherlands',' Scotland', ' Honduras', \n",
    "                                                                     ' Hungary', ' Outlying-US(Guam-USVI-etc)', ' Yugoslavia', \n",
    "                                                                     ' Laos', ' Thailand', ' Cambodia', \n",
    "                                                                     ' Trinadad&Tobago', ' Hong', ' Ireland', \n",
    "                                                                     ' France',' Ecuador', ' Greece', ' Peru', \n",
    "                                                                     ' Nicaragua', ' Portugal', ' Iran', \n",
    "                                                                     ' Taiwan', ' Haiti'], ' Other')\n",
    "train_data['native_country'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": " HS-grad         9840\n Some-college    6678\n Bachelors       5044\n Masters         1627\n Assoc-voc       1307\n 11th            1048\n Assoc-acdm      1008\n 10th             820\n 7th-8th          557\n Prof-school      542\n 9th              455\n 12th             377\n Doctorate        375\n 5th-6th          288\n 1st-4th          151\n Preschool         45\nName: education, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 125
    }
   ],
   "source": [
    "# 最后，看看education_num这个连续量\n",
    "train_data['education'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "# 发现跟education一样的，重复了，因为eudcation是离散的，不好处理。去掉这个属性\n",
    "train_data = train_data.drop(columns=['education'])\n",
    "test_data = test_data.drop(columns=['education'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "                     age    fnlwgt  education_num  capital_gain  capital_loss  \\\nage             1.000000 -0.076511       0.043526      0.080154      0.060165   \nfnlwgt         -0.076511  1.000000      -0.044992      0.000422     -0.009750   \neducation_num   0.043526 -0.044992       1.000000      0.124416      0.079646   \ncapital_gain    0.080154  0.000422       0.124416      1.000000     -0.032229   \ncapital_loss    0.060165 -0.009750       0.079646     -0.032229      1.000000   \nhours_per_week  0.101599 -0.022886       0.152522      0.080432      0.052417   \nincome          0.241998 -0.008957       0.335286      0.221196      0.150053   \n\n                hours_per_week    income  \nage                   0.101599  0.241998  \nfnlwgt               -0.022886 -0.008957  \neducation_num         0.152522  0.335286  \ncapital_gain          0.080432  0.221196  \ncapital_loss          0.052417  0.150053  \nhours_per_week        1.000000  0.229480  \nincome                0.229480  1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>fnlwgt</th>\n      <th>education_num</th>\n      <th>capital_gain</th>\n      <th>capital_loss</th>\n      <th>hours_per_week</th>\n      <th>income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age</th>\n      <td>1.000000</td>\n      <td>-0.076511</td>\n      <td>0.043526</td>\n      <td>0.080154</td>\n      <td>0.060165</td>\n      <td>0.101599</td>\n      <td>0.241998</td>\n    </tr>\n    <tr>\n      <th>fnlwgt</th>\n      <td>-0.076511</td>\n      <td>1.000000</td>\n      <td>-0.044992</td>\n      <td>0.000422</td>\n      <td>-0.009750</td>\n      <td>-0.022886</td>\n      <td>-0.008957</td>\n    </tr>\n    <tr>\n      <th>education_num</th>\n      <td>0.043526</td>\n      <td>-0.044992</td>\n      <td>1.000000</td>\n      <td>0.124416</td>\n      <td>0.079646</td>\n      <td>0.152522</td>\n      <td>0.335286</td>\n    </tr>\n    <tr>\n      <th>capital_gain</th>\n      <td>0.080154</td>\n      <td>0.000422</td>\n      <td>0.124416</td>\n      <td>1.000000</td>\n      <td>-0.032229</td>\n      <td>0.080432</td>\n      <td>0.221196</td>\n    </tr>\n    <tr>\n      <th>capital_loss</th>\n      <td>0.060165</td>\n      <td>-0.009750</td>\n      <td>0.079646</td>\n      <td>-0.032229</td>\n      <td>1.000000</td>\n      <td>0.052417</td>\n      <td>0.150053</td>\n    </tr>\n    <tr>\n      <th>hours_per_week</th>\n      <td>0.101599</td>\n      <td>-0.022886</td>\n      <td>0.152522</td>\n      <td>0.080432</td>\n      <td>0.052417</td>\n      <td>1.000000</td>\n      <td>0.229480</td>\n    </tr>\n    <tr>\n      <th>income</th>\n      <td>0.241998</td>\n      <td>-0.008957</td>\n      <td>0.335286</td>\n      <td>0.221196</td>\n      <td>0.150053</td>\n      <td>0.229480</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 127
    }
   ],
   "source": [
    "# 看看相关系数矩阵,检查一下连续变量。发现序号属性不太影响最后的收入\n",
    "train_data.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "# 把序号属性删掉\n",
    "train_data = train_data.drop(columns=['fnlwgt'])\n",
    "test_data = test_data.drop(columns=['fnlwgt'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "# 进行哑编码\n",
    "train_data = pd.get_dummies(train_data, columns=['workclass', 'marital_status', 'occupation',\n",
    "                                                 'relationship', 'race', 'sex',\n",
    "                                                 'native_country'])\n",
    "train_data\n",
    "\n",
    "test_data = pd.get_dummies(test_data, columns=['workclass', 'marital_status', 'occupation',\n",
    "                                                 'relationship', 'race', 'sex',\n",
    "                                                 'native_country'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['age', 'education_num', 'capital_gain', 'capital_loss',\n       'hours_per_week', 'income', 'workclass_ Federal-gov',\n       'workclass_ Local-gov', 'workclass_ Private', 'workclass_ Self-emp-inc',\n       'workclass_ Self-emp-not-inc', 'workclass_ State-gov',\n       'workclass_ Without-pay', 'marital_status_ Divorced',\n       'marital_status_ Married-AF-spouse',\n       'marital_status_ Married-civ-spouse',\n       'marital_status_ Married-spouse-absent',\n       'marital_status_ Never-married', 'marital_status_ Separated',\n       'marital_status_ Widowed', 'occupation_ Adm-clerical',\n       'occupation_ Armed-Forces', 'occupation_ Craft-repair',\n       'occupation_ Exec-managerial', 'occupation_ Farming-fishing',\n       'occupation_ Handlers-cleaners', 'occupation_ Machine-op-inspct',\n       'occupation_ Other-service', 'occupation_ Priv-house-serv',\n       'occupation_ Prof-specialty', 'occupation_ Protective-serv',\n       'occupation_ Sales', 'occupation_ Tech-support',\n       'occupation_ Transport-moving', 'relationship_ Husband',\n       'relationship_ Not-in-family', 'relationship_ Other-relative',\n       'relationship_ Own-child', 'relationship_ Unmarried',\n       'relationship_ Wife', 'race_ Amer-Indian-Eskimo',\n       'race_ Asian-Pac-Islander', 'race_ Black', 'race_ Other', 'race_ White',\n       'sex_ Female', 'sex_ Male', 'native_country_ Cambodia',\n       'native_country_ Canada', 'native_country_ China',\n       'native_country_ Columbia', 'native_country_ Cuba',\n       'native_country_ Dominican-Republic', 'native_country_ Ecuador',\n       'native_country_ El-Salvador', 'native_country_ England',\n       'native_country_ France', 'native_country_ Germany',\n       'native_country_ Greece', 'native_country_ Guatemala',\n       'native_country_ Haiti', 'native_country_ Holand-Netherlands',\n       'native_country_ Honduras', 'native_country_ Hong',\n       'native_country_ Hungary', 'native_country_ India',\n       'native_country_ Iran', 'native_country_ Ireland',\n       'native_country_ Italy', 'native_country_ Jamaica',\n       'native_country_ Japan', 'native_country_ Laos',\n       'native_country_ Mexico', 'native_country_ Nicaragua',\n       'native_country_ Outlying-US(Guam-USVI-etc)', 'native_country_ Peru',\n       'native_country_ Philippines', 'native_country_ Poland',\n       'native_country_ Portugal', 'native_country_ Puerto-Rico',\n       'native_country_ Scotland', 'native_country_ South',\n       'native_country_ Taiwan', 'native_country_ Thailand',\n       'native_country_ Trinadad&Tobago', 'native_country_ United-States',\n       'native_country_ Vietnam', 'native_country_ Yugoslavia'],\n      dtype='object')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 130
    }
   ],
   "source": [
    "# 看看编码后的结果\n",
    "train_data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "# 将非2值类型的数据进行标准化\n",
    "num = [x for x in train_data.columns if train_data[x].dtype=='int64']\n",
    "scaler = StandardScaler()\n",
    "train_data.loc[:, num] = scaler.fit_transform(train_data.loc[:, num])\n",
    "test_data.loc[:, num] = scaler.fit_transform(test_data.loc[:, num])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(30162, 87)\n",
      "(30162,)\n",
      "(15060, 86)\n",
      "(15060,)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 把要预测的值income单独拿出来看看\n",
    "y_train = np.array(train_data.income)\n",
    "x_train = np.array(train_data.drop('income', axis=1))\n",
    "\n",
    "y_test = np.array(test_data.income)\n",
    "x_test = np.array(test_data.drop('income', axis=1))\n",
    "\n",
    "x_train, x_eval, y_train, y_eval = train_test_split(x_train, y_train, test_size=0.2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-c28144ef7db6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_16_input to have shape (59,) but got array with shape (87,)"
     ],
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_16_input to have shape (59,) but got array with shape (87,)",
     "output_type": "error"
    }
   ],
   "source": [
    "# 搭建一个神经网络\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(units=32, activation='relu', input_dim=59))\n",
    "model.add(layers.Dense(units=16, activation='relu'))\n",
    "model.add((layers.Dense(units=1, activation='relu')))\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# confusion_matrix\n",
    "y_pred = model.predict_classes(x_test)\n",
    "y_pred = y_pred.astype(int)\n",
    "ann_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "types = ['0', '1']\n",
    "plot_confusion_matrix(ann_confusion_matrix, classes=types, normalize=False,\n",
    "                      title='confusion matrix for ANN')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}